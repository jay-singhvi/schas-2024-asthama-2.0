{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in c:\\program files\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\program files\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deep_translator in c:\\users\\41222\\appdata\\roaming\\python\\python312\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\program files\\python312\\lib\\site-packages (from deep_translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\41222\\appdata\\roaming\\python\\python312\\site-packages (from deep_translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\program files\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\41222\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\41222\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\41222\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python312\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2024.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: msoffcrypto-tool in c:\\program files\\python312\\lib\\site-packages (5.4.2)\n",
      "Requirement already satisfied: cryptography>=39.0 in c:\\program files\\python312\\lib\\site-packages (from msoffcrypto-tool) (43.0.0)\n",
      "Requirement already satisfied: olefile>=0.46 in c:\\program files\\python312\\lib\\site-packages (from msoffcrypto-tool) (0.47)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\program files\\python312\\lib\\site-packages (from cryptography>=39.0->msoffcrypto-tool) (1.17.0)\n",
      "Requirement already satisfied: pycparser in c:\\program files\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=39.0->msoffcrypto-tool) (2.22)\n"
     ]
    }
   ],
   "source": [
    "! pip install openpyxl\n",
    "! pip install --upgrade deep_translator\n",
    "! pip install msoffcrypto-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating occupation column...\n",
      "Translating address column...\n",
      "       ID  Age Sex Smoke  Smoke_amount  Height  Weight        BMI       BSA  \\\n",
      "0  SB-001   43   M    NS             0     156      76  31.229454  1.814754   \n",
      "1  SB-002   66   M    NS             0     163      58  21.829952  1.620528   \n",
      "2  SB-003   61   M    ES            20     173      67  22.386314  1.794358   \n",
      "3  SB-004   49   M    NS             0     142      51  25.292601  1.418332   \n",
      "4  SB-005   53   M    NS             0     156      70  28.763971  1.741647   \n",
      "\n",
      "  occupation                         address  occupation_en  \\\n",
      "0         주부            경기도 시흥시 마유로 443번길 1     : HOUSEWIFE   \n",
      "1        제조업   경기 부천시 원미구 중동 무지개마을 1201-1602  Manufacturing   \n",
      "2         타일                 인천시 부평구 수변로 333           Tile   \n",
      "3         주부                인천 서구 연희동 799-14    : HOUSEWIFE   \n",
      "4        무응답  경기 부천시 원미구 상3동 라일락마을 2333-1503      N/A&nbsp;   \n",
      "\n",
      "                                          address_en  \n",
      "0      1, Mayu-ro 443beon-gil, Siheung-si, Gyeonggi-  \n",
      "1  1201-1602, Rainbow Village, Jungdong, Wonmi-gu...  \n",
      "2               333, Subyun-ro, Bupyeong-gu, Incheon  \n",
      "3               799-14 Yeonhui-dong, Seo-gu, Incheon  \n",
      "4  Lilac Village 2333-1503, Sang3-dong, Wonmi-gu,...  \n",
      "Processing complete. Data saved to '2024-Data-Cleaned/processed_data_asthma_patient_medinfo.csv'\n",
      "Medical Info Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Smoke_amount</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BSA</th>\n",
       "      <th>occupation</th>\n",
       "      <th>address</th>\n",
       "      <th>occupation_en</th>\n",
       "      <th>address_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SB-001</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>76</td>\n",
       "      <td>31.229454</td>\n",
       "      <td>1.814754</td>\n",
       "      <td>주부</td>\n",
       "      <td>경기도 시흥시 마유로 443번길 1</td>\n",
       "      <td>: HOUSEWIFE</td>\n",
       "      <td>1, Mayu-ro 443beon-gil, Siheung-si, Gyeonggi-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB-002</td>\n",
       "      <td>66</td>\n",
       "      <td>M</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>58</td>\n",
       "      <td>21.829952</td>\n",
       "      <td>1.620528</td>\n",
       "      <td>제조업</td>\n",
       "      <td>경기 부천시 원미구 중동 무지개마을 1201-1602</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>1201-1602, Rainbow Village, Jungdong, Wonmi-gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SB-003</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>ES</td>\n",
       "      <td>20</td>\n",
       "      <td>173</td>\n",
       "      <td>67</td>\n",
       "      <td>22.386314</td>\n",
       "      <td>1.794358</td>\n",
       "      <td>타일</td>\n",
       "      <td>인천시 부평구 수변로 333</td>\n",
       "      <td>Tile</td>\n",
       "      <td>333, Subyun-ro, Bupyeong-gu, Incheon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB-004</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>51</td>\n",
       "      <td>25.292601</td>\n",
       "      <td>1.418332</td>\n",
       "      <td>주부</td>\n",
       "      <td>인천 서구 연희동 799-14</td>\n",
       "      <td>: HOUSEWIFE</td>\n",
       "      <td>799-14 Yeonhui-dong, Seo-gu, Incheon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SB-005</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>70</td>\n",
       "      <td>28.763971</td>\n",
       "      <td>1.741647</td>\n",
       "      <td>무응답</td>\n",
       "      <td>경기 부천시 원미구 상3동 라일락마을 2333-1503</td>\n",
       "      <td>N/A&amp;nbsp;</td>\n",
       "      <td>Lilac Village 2333-1503, Sang3-dong, Wonmi-gu,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>SB-135</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>67</td>\n",
       "      <td>25.217359</td>\n",
       "      <td>1.741726</td>\n",
       "      <td>무직</td>\n",
       "      <td>부천시 원미구 도당동 137-4</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>137-4, Dodang-dong, Wonmi-gu, Bucheon-si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>SB-137</td>\n",
       "      <td>76</td>\n",
       "      <td>F</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>66</td>\n",
       "      <td>25.781250</td>\n",
       "      <td>1.712698</td>\n",
       "      <td>주부</td>\n",
       "      <td>경기도 부천시 부흥로 71</td>\n",
       "      <td>: HOUSEWIFE</td>\n",
       "      <td>71, Bupheung-ro, Bucheon-si, G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>SB-139</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>20</td>\n",
       "      <td>162</td>\n",
       "      <td>64</td>\n",
       "      <td>24.386526</td>\n",
       "      <td>1.697056</td>\n",
       "      <td>건설업</td>\n",
       "      <td>부천시 원미구 중2동 그린타운 한신A</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Hanshin A, Green Town, Jung 2-dong, Wonmi-gu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SB-140</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>15</td>\n",
       "      <td>170</td>\n",
       "      <td>72</td>\n",
       "      <td>24.913495</td>\n",
       "      <td>1.843909</td>\n",
       "      <td>건설업</td>\n",
       "      <td>부천시 원미구 중3동 중흥마을</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Jungheung Village, Jung 3-dong, Wonmi-gu, Buch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>SB-141</td>\n",
       "      <td>71</td>\n",
       "      <td>F</td>\n",
       "      <td>NS</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>73</td>\n",
       "      <td>27.815882</td>\n",
       "      <td>1.812457</td>\n",
       "      <td>기타</td>\n",
       "      <td>부천시 오정구 여월동 8-54</td>\n",
       "      <td>Others</td>\n",
       "      <td>8-54 Yeowol-dong, Ojeong-gu, Bucheon-si</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Age Sex Smoke  Smoke_amount  Height  Weight        BMI       BSA  \\\n",
       "0    SB-001   43   M    NS             0     156      76  31.229454  1.814754   \n",
       "1    SB-002   66   M    NS             0     163      58  21.829952  1.620528   \n",
       "2    SB-003   61   M    ES            20     173      67  22.386314  1.794358   \n",
       "3    SB-004   49   M    NS             0     142      51  25.292601  1.418332   \n",
       "4    SB-005   53   M    NS             0     156      70  28.763971  1.741647   \n",
       "..      ...  ...  ..   ...           ...     ...     ...        ...       ...   \n",
       "109  SB-135   79   M    NS             0     163      67  25.217359  1.741726   \n",
       "110  SB-137   76   F    NS             0     160      66  25.781250  1.712698   \n",
       "111  SB-139   50   F    ES            20     162      64  24.386526  1.697056   \n",
       "112  SB-140   69   F    ES            15     170      72  24.913495  1.843909   \n",
       "113  SB-141   71   F    NS             0     162      73  27.815882  1.812457   \n",
       "\n",
       "    occupation                         address  occupation_en  \\\n",
       "0           주부            경기도 시흥시 마유로 443번길 1     : HOUSEWIFE   \n",
       "1          제조업   경기 부천시 원미구 중동 무지개마을 1201-1602  Manufacturing   \n",
       "2           타일                 인천시 부평구 수변로 333           Tile   \n",
       "3           주부                인천 서구 연희동 799-14    : HOUSEWIFE   \n",
       "4          무응답  경기 부천시 원미구 상3동 라일락마을 2333-1503      N/A&nbsp;   \n",
       "..         ...                             ...            ...   \n",
       "109         무직               부천시 원미구 도당동 137-4   Not Employed   \n",
       "110         주부                  경기도 부천시 부흥로 71    : HOUSEWIFE   \n",
       "111        건설업            부천시 원미구 중2동 그린타운 한신A   Construction   \n",
       "112        건설업                부천시 원미구 중3동 중흥마을   Construction   \n",
       "113         기타                부천시 오정구 여월동 8-54         Others   \n",
       "\n",
       "                                            address_en  \n",
       "0        1, Mayu-ro 443beon-gil, Siheung-si, Gyeonggi-  \n",
       "1    1201-1602, Rainbow Village, Jungdong, Wonmi-gu...  \n",
       "2                 333, Subyun-ro, Bupyeong-gu, Incheon  \n",
       "3                 799-14 Yeonhui-dong, Seo-gu, Incheon  \n",
       "4    Lilac Village 2333-1503, Sang3-dong, Wonmi-gu,...  \n",
       "..                                                 ...  \n",
       "109           137-4, Dodang-dong, Wonmi-gu, Bucheon-si  \n",
       "110                     71, Bupheung-ro, Bucheon-si, G  \n",
       "111  Hanshin A, Green Town, Jung 2-dong, Wonmi-gu, ...  \n",
       "112  Jungheung Village, Jung 3-dong, Wonmi-gu, Buch...  \n",
       "113            8-54 Yeowol-dong, Ojeong-gu, Bucheon-si  \n",
       "\n",
       "[114 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processing - PEFR_asthma_114_medinfo_07.15.xlsx\n",
    "import pandas as pd\n",
    "import io\n",
    "import msoffcrypto\n",
    "from deep_translator import MyMemoryTranslator\n",
    "\n",
    "\n",
    "def decrypt_excel_file(file_path, sheet_name, password):\n",
    "    # Decrypt the file\n",
    "    decrypted_workbook = io.BytesIO()\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        office_file = msoffcrypto.OfficeFile(file)\n",
    "        office_file.load_key(password=password)\n",
    "        office_file.decrypt(decrypted_workbook)\n",
    "\n",
    "    # Read the decrypted file into a pandas DataFrame\n",
    "    df = pd.read_excel(decrypted_workbook, sheet_name=sheet_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to translate text, handling empty/null values\n",
    "def translate_text(text):\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"No Response\"\n",
    "    try:\n",
    "        return MyMemoryTranslator(source=\"ko-KR\", target=\"en-US\").translate(str(text))\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text  # Return original text if translation fails\n",
    "\n",
    "\n",
    "def process_excel_file(file_path, password, sheet_name, output_file):\n",
    "    df = decrypt_excel_file(file_path, sheet_name, password)\n",
    "\n",
    "    # Drop specified columns\n",
    "    df = df.drop(columns=[\"BCODE\", \"UID1\", \"UID2\"])\n",
    "\n",
    "    # # Translate 'occupation' and 'address' columns\n",
    "    print(\"Translating occupation column...\")\n",
    "    df[\"occupation_en\"] = df[\"occupation\"].apply(translate_text)\n",
    "    print(\"Translating address column...\")\n",
    "    df[\"address_en\"] = df[\"address\"].apply(translate_text)\n",
    "\n",
    "    # Display the first few rows of the processed dataframe\n",
    "    print(df.head())\n",
    "\n",
    "    # Save the processed dataframe to a new CSV file\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(\n",
    "        \"Processing complete. Data saved to '2024-Data-Cleaned/processed_data_asthma_patient_medinfo.csv'\"\n",
    "    )\n",
    "\n",
    "    print(\"Medical Info Data\")\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Path to your password-protected Excel file\n",
    "file_path = \"2024-Data/PEFR_asthma_114_medinfo_07.15.xlsx\"\n",
    "password = \"1234\"\n",
    "sheet_name = \"PEFR_114명\"\n",
    "output_file = \"2024-Data-Cleaned/processed_data_asthma_patient_medinfo.csv\"\n",
    "\n",
    "patient_medical_info_df = process_excel_file(\n",
    "    file_path, password, sheet_name, output_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing file: SB-001 (2020-02-05).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (1336, 4)\n",
      "INFO:__main__:Cleaned data shape: (1336, 4)\n",
      "INFO:__main__:Processing file: SB-002 (2017-01-29).xlsx\n",
      "INFO:__main__:Original data shape: (572, 4)\n",
      "INFO:__main__:Cleaned data shape: (572, 4)\n",
      "INFO:__main__:Processing file: SB-003 (2020-03-29).xlsx\n",
      "INFO:__main__:Original data shape: (1064, 4)\n",
      "INFO:__main__:Cleaned data shape: (1064, 4)\n",
      "INFO:__main__:Processing file: SB-004 (2021-09-04).xlsx\n",
      "INFO:__main__:Original data shape: (1823, 4)\n",
      "INFO:__main__:Cleaned data shape: (1823, 4)\n",
      "INFO:__main__:Processing file: SB-005 (2017-03-11).xlsx\n",
      "INFO:__main__:Original data shape: (281, 4)\n",
      "INFO:__main__:Cleaned data shape: (281, 4)\n",
      "INFO:__main__:Processing file: SB-006 (2020-01-08).xlsx\n",
      "INFO:__main__:Original data shape: (1327, 4)\n",
      "INFO:__main__:Cleaned data shape: (1327, 4)\n",
      "INFO:__main__:Processing file: SB-007 (2017-05-15).xlsx\n",
      "INFO:__main__:Original data shape: (309, 4)\n",
      "INFO:__main__:Cleaned data shape: (309, 4)\n",
      "INFO:__main__:Processing file: SB-008 (2021-06-30).xlsx\n",
      "INFO:__main__:Original data shape: (2100, 4)\n",
      "INFO:__main__:Cleaned data shape: (2100, 4)\n",
      "INFO:__main__:Processing file: SB-009 (2019-04-09).xlsx\n",
      "INFO:__main__:Original data shape: (975, 4)\n",
      "INFO:__main__:Cleaned data shape: (975, 4)\n",
      "INFO:__main__:Processing file: SB-010 (2017-07-24).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (266, 4)\n",
      "INFO:__main__:Cleaned data shape: (266, 4)\n",
      "INFO:__main__:Processing file: SB-011 (2022-01-19).xlsx\n",
      "INFO:__main__:Original data shape: (2093, 4)\n",
      "INFO:__main__:Cleaned data shape: (2093, 4)\n",
      "INFO:__main__:Processing file: SB-012 (2018-05-15).xlsx\n",
      "INFO:__main__:Original data shape: (594, 4)\n",
      "INFO:__main__:Cleaned data shape: (594, 4)\n",
      "INFO:__main__:Processing file: SB-013 (2017-03-18).xlsx\n",
      "INFO:__main__:Original data shape: (773, 4)\n",
      "INFO:__main__:Cleaned data shape: (773, 4)\n",
      "INFO:__main__:Processing file: SB-014 (2022-01-10).xlsx\n",
      "INFO:__main__:Original data shape: (1793, 4)\n",
      "INFO:__main__:Cleaned data shape: (1793, 4)\n",
      "INFO:__main__:Processing file: SB-015 (2018-05-20).xlsx\n",
      "INFO:__main__:Original data shape: (640, 4)\n",
      "INFO:__main__:Cleaned data shape: (640, 4)\n",
      "INFO:__main__:Processing file: SB-016 (2018-01-31).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (667, 4)\n",
      "INFO:__main__:Cleaned data shape: (667, 4)\n",
      "INFO:__main__:Processing file: SB-017 (2021-11-30).xlsx\n",
      "INFO:__main__:Original data shape: (1990, 4)\n",
      "INFO:__main__:Cleaned data shape: (1990, 4)\n",
      "INFO:__main__:Processing file: SB-018 (2017-09-13).xlsx\n",
      "INFO:__main__:Original data shape: (309, 4)\n",
      "INFO:__main__:Cleaned data shape: (309, 4)\n",
      "INFO:__main__:Processing file: SB-019 (2018-05-26).xlsx\n",
      "INFO:__main__:Original data shape: (648, 4)\n",
      "INFO:__main__:Cleaned data shape: (648, 4)\n",
      "INFO:__main__:Processing file: SB-020 (2017-10-12).xlsx\n",
      "INFO:__main__:Original data shape: (422, 4)\n",
      "INFO:__main__:Cleaned data shape: (422, 4)\n",
      "INFO:__main__:Processing file: SB-021 (2017-09-12).xlsx\n",
      "INFO:__main__:Original data shape: (194, 4)\n",
      "INFO:__main__:Cleaned data shape: (194, 4)\n",
      "INFO:__main__:Processing file: SB-022 (2021-04-30).xlsx\n",
      "INFO:__main__:Original data shape: (1522, 4)\n",
      "INFO:__main__:Cleaned data shape: (1522, 4)\n",
      "INFO:__main__:Processing file: SB-023 (2020-04-06).xlsx\n",
      "INFO:__main__:Original data shape: (1422, 4)\n",
      "INFO:__main__:Cleaned data shape: (1422, 4)\n",
      "INFO:__main__:Processing file: SB-024 (2017-08-30).xlsx\n",
      "INFO:__main__:Original data shape: (483, 4)\n",
      "INFO:__main__:Cleaned data shape: (483, 4)\n",
      "INFO:__main__:Processing file: SB-025 (2019-10-14).xlsx\n",
      "INFO:__main__:Original data shape: (1259, 4)\n",
      "INFO:__main__:Cleaned data shape: (1259, 4)\n",
      "INFO:__main__:Processing file: SB-026 (2018-02-26).xlsx\n",
      "INFO:__main__:Original data shape: (308, 4)\n",
      "INFO:__main__:Cleaned data shape: (308, 4)\n",
      "INFO:__main__:Processing file: SB-028 (2018-08-08).xlsx\n",
      "INFO:__main__:Original data shape: (395, 4)\n",
      "INFO:__main__:Cleaned data shape: (395, 4)\n",
      "INFO:__main__:Processing file: SB-029 (2020-04-19).xlsx\n",
      "INFO:__main__:Original data shape: (1434, 4)\n",
      "INFO:__main__:Cleaned data shape: (1434, 4)\n",
      "INFO:__main__:Processing file: SB-031 (2018-05-15).xlsx\n",
      "INFO:__main__:Original data shape: (574, 4)\n",
      "INFO:__main__:Cleaned data shape: (574, 4)\n",
      "INFO:__main__:Processing file: SB-032 (2017-10-10).xlsx\n",
      "INFO:__main__:Original data shape: (62, 4)\n",
      "INFO:__main__:Cleaned data shape: (62, 4)\n",
      "INFO:__main__:Processing file: SB-033 (2020-03-28).xlsx\n",
      "INFO:__main__:Original data shape: (1208, 4)\n",
      "INFO:__main__:Cleaned data shape: (1208, 4)\n",
      "INFO:__main__:Processing file: SB-035 (2017-09-11).xlsx\n",
      "INFO:__main__:Original data shape: (447, 4)\n",
      "INFO:__main__:Cleaned data shape: (447, 4)\n",
      "INFO:__main__:Processing file: SB-036 (2019-10-13).xlsx\n",
      "INFO:__main__:Original data shape: (1260, 4)\n",
      "INFO:__main__:Cleaned data shape: (1260, 4)\n",
      "INFO:__main__:Processing file: SB-037 (2018-07-23).xlsx\n",
      "INFO:__main__:Original data shape: (326, 4)\n",
      "INFO:__main__:Cleaned data shape: (326, 4)\n",
      "INFO:__main__:Processing file: SB-039 (2017-05-31).xlsx\n",
      "INFO:__main__:Original data shape: (363, 4)\n",
      "INFO:__main__:Cleaned data shape: (363, 4)\n",
      "INFO:__main__:Processing file: SB-040 (2021-09-30).xlsx\n",
      "INFO:__main__:Original data shape: (1934, 4)\n",
      "INFO:__main__:Cleaned data shape: (1934, 4)\n",
      "INFO:__main__:Processing file: SB-042 (2019-05-20).xlsx\n",
      "INFO:__main__:Original data shape: (1131, 4)\n",
      "INFO:__main__:Cleaned data shape: (1131, 4)\n",
      "INFO:__main__:Processing file: SB-043 (2020-04-01).xlsx\n",
      "INFO:__main__:Original data shape: (1385, 4)\n",
      "INFO:__main__:Cleaned data shape: (1385, 4)\n",
      "INFO:__main__:Processing file: SB-044 (2019-04-03).xlsx\n",
      "INFO:__main__:Original data shape: (689, 4)\n",
      "INFO:__main__:Cleaned data shape: (689, 4)\n",
      "INFO:__main__:Processing file: SB-046 (2017-10-11).xlsx\n",
      "INFO:__main__:Original data shape: (12, 4)\n",
      "INFO:__main__:Cleaned data shape: (12, 4)\n",
      "INFO:__main__:Processing file: SB-047 (2020-06-08).xlsx\n",
      "INFO:__main__:Original data shape: (1526, 4)\n",
      "INFO:__main__:Cleaned data shape: (1526, 4)\n",
      "INFO:__main__:Processing file: SB-048 (2021-04-19).xlsx\n",
      "INFO:__main__:Original data shape: (1621, 4)\n",
      "INFO:__main__:Cleaned data shape: (1621, 4)\n",
      "INFO:__main__:Processing file: SB-049 (2019-09-23).xlsx\n",
      "INFO:__main__:Original data shape: (1079, 4)\n",
      "INFO:__main__:Cleaned data shape: (1079, 4)\n",
      "INFO:__main__:Processing file: SB-050 (2018-03-09).xlsx\n",
      "INFO:__main__:Original data shape: (615, 4)\n",
      "INFO:__main__:Cleaned data shape: (615, 4)\n",
      "INFO:__main__:Processing file: SB-051 (2017-01-29).xlsx\n",
      "INFO:__main__:Original data shape: (340, 4)\n",
      "INFO:__main__:Cleaned data shape: (340, 4)\n",
      "INFO:__main__:Processing file: SB-052 (2017-03-08).xlsx\n",
      "INFO:__main__:Original data shape: (386, 4)\n",
      "INFO:__main__:Cleaned data shape: (386, 4)\n",
      "INFO:__main__:Processing file: SB-053 (2018-11-06).xlsx\n",
      "INFO:__main__:Original data shape: (338, 4)\n",
      "INFO:__main__:Cleaned data shape: (338, 4)\n",
      "INFO:__main__:Processing file: SB-054 (2017-04-27).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (322, 4)\n",
      "INFO:__main__:Cleaned data shape: (322, 4)\n",
      "INFO:__main__:Processing file: SB-055 (2017-04-24).xlsx\n",
      "INFO:__main__:Original data shape: (585, 4)\n",
      "INFO:__main__:Cleaned data shape: (585, 4)\n",
      "INFO:__main__:Processing file: SB-056 (2020-10-28).xlsx\n",
      "INFO:__main__:Original data shape: (1485, 4)\n",
      "INFO:__main__:Cleaned data shape: (1485, 4)\n",
      "INFO:__main__:Processing file: SB-057 (2017-07-20).xlsx\n",
      "INFO:__main__:Original data shape: (256, 4)\n",
      "INFO:__main__:Cleaned data shape: (256, 4)\n",
      "INFO:__main__:Processing file: SB-058 (2021-11-29).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (292, 4)\n",
      "INFO:__main__:Cleaned data shape: (292, 4)\n",
      "INFO:__main__:Processing file: SB-059 (2021-10-06).xlsx\n",
      "INFO:__main__:Original data shape: (1836, 4)\n",
      "INFO:__main__:Cleaned data shape: (1836, 4)\n",
      "INFO:__main__:Processing file: SB-060 (2018-02-25).xlsx\n",
      "INFO:__main__:Original data shape: (388, 4)\n",
      "INFO:__main__:Cleaned data shape: (388, 4)\n",
      "INFO:__main__:Processing file: SB-061 (2017-05-24).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (337, 4)\n",
      "INFO:__main__:Cleaned data shape: (337, 4)\n",
      "INFO:__main__:Processing file: SB-062 (2017-10-16).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (500, 4)\n",
      "INFO:__main__:Cleaned data shape: (500, 4)\n",
      "INFO:__main__:Processing file: SB-063 (2019-04-21).xlsx\n",
      "INFO:__main__:Original data shape: (955, 4)\n",
      "INFO:__main__:Cleaned data shape: (955, 4)\n",
      "INFO:__main__:Processing file: SB-064 (2020-05-10).xlsx\n",
      "INFO:__main__:Original data shape: (1167, 4)\n",
      "INFO:__main__:Cleaned data shape: (1167, 4)\n",
      "INFO:__main__:Processing file: SB-065 (2017-02-28).xlsx\n",
      "INFO:__main__:Original data shape: (340, 4)\n",
      "INFO:__main__:Cleaned data shape: (340, 4)\n",
      "INFO:__main__:Processing file: SB-066 (2017-08-14).xlsx\n",
      "INFO:__main__:Original data shape: (270, 4)\n",
      "INFO:__main__:Cleaned data shape: (270, 4)\n",
      "INFO:__main__:Processing file: SB-067 (2018-12-17).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (980, 4)\n",
      "INFO:__main__:Cleaned data shape: (980, 4)\n",
      "INFO:__main__:Processing file: SB-068 (2021-01-31).xlsx\n",
      "INFO:__main__:Original data shape: (1704, 4)\n",
      "INFO:__main__:Cleaned data shape: (1704, 4)\n",
      "INFO:__main__:Processing file: SB-070 (2019-10-16).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (1254, 4)\n",
      "INFO:__main__:Cleaned data shape: (1254, 4)\n",
      "INFO:__main__:Processing file: SB-071 (2018-08-31).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (1005, 4)\n",
      "INFO:__main__:Cleaned data shape: (1005, 4)\n",
      "INFO:__main__:Processing file: SB-072 (2021-10-18).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (1898, 4)\n",
      "INFO:__main__:Cleaned data shape: (1898, 4)\n",
      "INFO:__main__:Processing file: SB-073 (2021-04-03).xlsx\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "WARNING:__main__:Unable to parse date: A04\n",
      "INFO:__main__:Original data shape: (1833, 4)\n",
      "INFO:__main__:Cleaned data shape: (1833, 4)\n",
      "INFO:__main__:Processing file: SB-074 (2017-03-13).xlsx\n",
      "INFO:__main__:Original data shape: (337, 4)\n",
      "INFO:__main__:Cleaned data shape: (337, 4)\n",
      "INFO:__main__:Processing file: SB-075 (2019-03-18).xlsx\n",
      "INFO:__main__:Original data shape: (949, 4)\n",
      "INFO:__main__:Cleaned data shape: (949, 4)\n",
      "INFO:__main__:Processing file: SB-077 (2018-05-14).xlsx\n",
      "INFO:__main__:Original data shape: (498, 4)\n",
      "INFO:__main__:Cleaned data shape: (498, 4)\n",
      "INFO:__main__:Processing file: SB-078 (2019-04-17).xlsx\n",
      "INFO:__main__:Original data shape: (486, 4)\n",
      "INFO:__main__:Cleaned data shape: (486, 4)\n",
      "INFO:__main__:Processing file: SB-079 (2021-12-30).xlsx\n",
      "INFO:__main__:Original data shape: (2039, 4)\n",
      "INFO:__main__:Cleaned data shape: (2039, 4)\n",
      "INFO:__main__:Processing file: SB-080 (2019-04-27).xlsx\n",
      "INFO:__main__:Original data shape: (625, 4)\n",
      "INFO:__main__:Cleaned data shape: (625, 4)\n",
      "INFO:__main__:Processing file: SB-081 (2021-04-05).xlsx\n",
      "INFO:__main__:Original data shape: (1845, 4)\n",
      "INFO:__main__:Cleaned data shape: (1845, 4)\n",
      "INFO:__main__:Processing file: SB-082 (2019-03-11).xlsx\n",
      "INFO:__main__:Original data shape: (1064, 4)\n",
      "INFO:__main__:Cleaned data shape: (1064, 4)\n",
      "INFO:__main__:Processing file: SB-083 (2018-06-04).xlsx\n",
      "INFO:__main__:Original data shape: (382, 4)\n",
      "INFO:__main__:Cleaned data shape: (382, 4)\n",
      "INFO:__main__:Processing file: SB-084 (2021-02-23).xlsx\n",
      "INFO:__main__:Original data shape: (1756, 4)\n",
      "INFO:__main__:Cleaned data shape: (1756, 4)\n",
      "INFO:__main__:Processing file: SB-085 (2020-07-31).xlsx\n",
      "INFO:__main__:Original data shape: (1541, 4)\n",
      "INFO:__main__:Cleaned data shape: (1541, 4)\n",
      "INFO:__main__:Processing file: SB-086 (2017-10-10).xlsx\n",
      "INFO:__main__:Original data shape: (513, 4)\n",
      "INFO:__main__:Cleaned data shape: (513, 4)\n",
      "INFO:__main__:Processing file: SB-088 (2021-05-31).xlsx\n",
      "INFO:__main__:Original data shape: (2002, 4)\n",
      "INFO:__main__:Cleaned data shape: (2002, 4)\n",
      "INFO:__main__:Processing file: SB-089 (2021-05-02).xlsx\n",
      "INFO:__main__:Original data shape: (1811, 4)\n",
      "INFO:__main__:Cleaned data shape: (1811, 4)\n",
      "INFO:__main__:Processing file: SB-091 (2018-07-31).xlsx\n",
      "INFO:__main__:Original data shape: (396, 4)\n",
      "INFO:__main__:Cleaned data shape: (396, 4)\n",
      "INFO:__main__:Processing file: SB-092 (2020-06-30).xlsx\n",
      "INFO:__main__:Original data shape: (1055, 4)\n",
      "INFO:__main__:Cleaned data shape: (1055, 4)\n",
      "INFO:__main__:Processing file: SB-093 (2019-03-19).xlsx\n",
      "INFO:__main__:Original data shape: (861, 4)\n",
      "INFO:__main__:Cleaned data shape: (861, 4)\n",
      "INFO:__main__:Processing file: SB-095 (2021-06-30).xlsx\n",
      "INFO:__main__:Original data shape: (1016, 4)\n",
      "INFO:__main__:Cleaned data shape: (1016, 4)\n",
      "INFO:__main__:Processing file: SB-096 (2020-05-04).xlsx\n",
      "INFO:__main__:Original data shape: (600, 4)\n",
      "INFO:__main__:Cleaned data shape: (600, 4)\n",
      "INFO:__main__:Processing file: SB-099 (2018-01-31).xlsx\n",
      "INFO:__main__:Original data shape: (321, 4)\n",
      "INFO:__main__:Cleaned data shape: (321, 4)\n",
      "INFO:__main__:Processing file: SB-101 (2018-05-28).xlsx\n",
      "INFO:__main__:Original data shape: (613, 4)\n",
      "INFO:__main__:Cleaned data shape: (613, 4)\n",
      "INFO:__main__:Processing file: SB-102 (2016-06-05).xlsx\n",
      "INFO:__main__:Original data shape: (372, 4)\n",
      "INFO:__main__:Cleaned data shape: (372, 4)\n",
      "INFO:__main__:Processing file: SB-108 (2019-01-16).xlsx\n",
      "INFO:__main__:Original data shape: (975, 4)\n",
      "INFO:__main__:Cleaned data shape: (975, 4)\n",
      "INFO:__main__:Processing file: SB-110 (2019-02-23).xlsx\n",
      "INFO:__main__:Original data shape: (346, 4)\n",
      "INFO:__main__:Cleaned data shape: (346, 4)\n",
      "INFO:__main__:Processing file: SB-111 (2017-08-28).xlsx\n",
      "INFO:__main__:Original data shape: (274, 4)\n",
      "INFO:__main__:Cleaned data shape: (274, 4)\n",
      "INFO:__main__:Processing file: SB-112 (2021-10-29.xlsx\n",
      "INFO:__main__:Original data shape: (1535, 4)\n",
      "INFO:__main__:Cleaned data shape: (1535, 4)\n",
      "INFO:__main__:Processing file: SB-115 (2020-04-29).xlsx\n",
      "INFO:__main__:Original data shape: (1247, 4)\n",
      "INFO:__main__:Cleaned data shape: (1247, 4)\n",
      "INFO:__main__:Processing file: SB-116 (2018-04-02).xlsx\n",
      "INFO:__main__:Original data shape: (319, 4)\n",
      "INFO:__main__:Cleaned data shape: (319, 4)\n",
      "INFO:__main__:Processing file: SB-117 (2019-02-13).xlsx\n",
      "INFO:__main__:Original data shape: (278, 4)\n",
      "INFO:__main__:Cleaned data shape: (278, 4)\n",
      "INFO:__main__:Processing file: SB-118 (2018-07-12).xlsx\n",
      "INFO:__main__:Original data shape: (93, 4)\n",
      "INFO:__main__:Cleaned data shape: (93, 4)\n",
      "INFO:__main__:Processing file: SB-119 (2018-12-17).xlsx\n",
      "INFO:__main__:Original data shape: (624, 4)\n",
      "INFO:__main__:Cleaned data shape: (624, 4)\n",
      "INFO:__main__:Processing file: SB-120 (2018-07-18).xlsx\n",
      "INFO:__main__:Original data shape: (199, 4)\n",
      "INFO:__main__:Cleaned data shape: (199, 4)\n",
      "INFO:__main__:Processing file: SB-121 (2019-07-15).xlsx\n",
      "INFO:__main__:Original data shape: (979, 4)\n",
      "INFO:__main__:Cleaned data shape: (979, 4)\n",
      "INFO:__main__:Processing file: SB-122 (2022-01-19).xlsx\n",
      "INFO:__main__:Original data shape: (2036, 4)\n",
      "INFO:__main__:Cleaned data shape: (2036, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from datetime import datetime\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "\n",
    "def parse_date_column(date_str):\n",
    "    for date_format in [\"%Y-%m-%d\", \"%d-%m-%Y\", \"%m/%d/%Y\", \"%Y/%m/%d\"]:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=date_format).date()\n",
    "        except ValueError:\n",
    "            logger.warning(f\"Unable to parse date: {date_str}\")\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def clean_data(df, filename, patient_id):\n",
    "\n",
    "    logger.info(f\"Processing file: {filename}\")\n",
    "\n",
    "    # Find the index of the row where the third column (original G) is \"Morning\"\n",
    "    morning_row_index = df.index[df.iloc[:, 1] == \"Morning\"].tolist()\n",
    "    if morning_row_index:\n",
    "\n",
    "        # If \"Morning\" is found, set that row as header and remove it from the data\n",
    "        header_row = morning_row_index[0]\n",
    "        df.columns = df.iloc[header_row]\n",
    "        df = df.drop(df.index[: header_row + 1]).reset_index(drop=True)\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: 'Morning' not found in column G for file {filename}\")\n",
    "\n",
    "        # If \"Morning\" is not found, use default column names\n",
    "        df.columns = [\"B\", \"G\", \"H\", \"I\"]\n",
    "\n",
    "    # Replace empty cells or whitespace-only cells with NaN\n",
    "    df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "\n",
    "    # Drop rows where all cells are NaN\n",
    "    df = df.dropna(how=\"all\")\n",
    "    df.columns = [\"Date\", \"Morning\", \"Afternoon\", \"Other\"]\n",
    "\n",
    "    # Parse dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(parse_date_column)\n",
    "\n",
    "    # Remove rows where date parsing failed\n",
    "    df = df.dropna(subset=[\"Date\"])\n",
    "\n",
    "    # Convert 'Date' column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Convert 'Morning', 'Afternoon', and 'Other' columns to numeric, coercing errors to NaN\n",
    "    for col in [\"Morning\", \"Afternoon\", \"Other\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Handle 'Other' column\n",
    "    mask = df[\"Other\"].notna()\n",
    "\n",
    "    logger.info(f\"Original data shape: {df.shape}\")\n",
    "    df.to_csv(f\"2024-Data-Cleaned/Original_Data/{patient_id}-OG.csv\", index=False)\n",
    "\n",
    "    # Move 'Other' to 'Morning' if 'Morning' is empty\n",
    "    morning_mask = mask & df[\"Morning\"].isna()\n",
    "    df.loc[morning_mask, \"Morning\"] = df.loc[morning_mask, \"Other\"]\n",
    "    df.loc[morning_mask, \"Other\"] = np.nan\n",
    "\n",
    "    # Move 'Other' to 'Afternoon' if 'Afternoon' is empty and 'Other' still has value\n",
    "    mask = df[\"Other\"].notna()  # Recalculate mask\n",
    "    afternoon_mask = mask & df[\"Afternoon\"].isna()\n",
    "    df.loc[afternoon_mask, \"Afternoon\"] = df.loc[afternoon_mask, \"Other\"]\n",
    "    df.loc[afternoon_mask, \"Other\"] = np.nan\n",
    "\n",
    "    if df.empty:\n",
    "        logger.warning(f\"Cleaned dataframe is empty for file {filename}\")\n",
    "        return None\n",
    "\n",
    "    logger.info(f\"Cleaned data shape: {df.shape}\")\n",
    "    df.to_csv(f\"2024-Data-Cleaned/Cleaned_Data/{patient_id}-Clean.csv\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_and_clean_data(folder_path):\n",
    "    patient_data_dict = {}\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    Original_Data_dir = \"2024-Data-Cleaned/Original_Data\"\n",
    "    os.makedirs(Original_Data_dir, exist_ok=True)\n",
    "    Cleaned_Data_dir = \"2024-Data-Cleaned/Cleaned_Data\"\n",
    "    os.makedirs(Cleaned_Data_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        patient_id = filename.split(\" \")[0]\n",
    "        # Read the file without setting a header initially\n",
    "        df = pd.read_excel(\n",
    "            os.path.join(folder_path, filename),\n",
    "            sheet_name=\"Database\",\n",
    "            engine=\"openpyxl\",\n",
    "            header=None,\n",
    "            usecols=[1, 6, 7, 8],\n",
    "        )  # 0-based index for columns B, G, H, I\n",
    "        patient_data_dict[patient_id] = clean_data(df, filename, patient_id)\n",
    "\n",
    "    return patient_data_dict\n",
    "\n",
    "\n",
    "cleaned_patient_data_dict = load_and_clean_data(folder_path=\"2024-Data/SCH_asthma_114/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Imputed data shape: (1336, 4)\n",
      "INFO:__main__:Imputed data shape: (572, 4)\n",
      "INFO:__main__:Imputed data shape: (1064, 4)\n",
      "INFO:__main__:Imputed data shape: (1823, 4)\n",
      "INFO:__main__:Imputed data shape: (281, 4)\n",
      "INFO:__main__:Imputed data shape: (1327, 4)\n",
      "INFO:__main__:Imputed data shape: (309, 4)\n",
      "INFO:__main__:Imputed data shape: (2100, 4)\n",
      "INFO:__main__:Imputed data shape: (975, 4)\n",
      "INFO:__main__:Imputed data shape: (266, 4)\n",
      "INFO:__main__:Imputed data shape: (2093, 4)\n",
      "INFO:__main__:Imputed data shape: (594, 4)\n",
      "INFO:__main__:Imputed data shape: (773, 4)\n",
      "INFO:__main__:Imputed data shape: (1793, 4)\n",
      "INFO:__main__:Imputed data shape: (640, 4)\n",
      "INFO:__main__:Imputed data shape: (667, 4)\n",
      "INFO:__main__:Imputed data shape: (1990, 4)\n",
      "INFO:__main__:Imputed data shape: (309, 4)\n",
      "INFO:__main__:Imputed data shape: (648, 4)\n",
      "INFO:__main__:Imputed data shape: (422, 4)\n",
      "INFO:__main__:Imputed data shape: (194, 4)\n",
      "INFO:__main__:Imputed data shape: (1522, 4)\n",
      "INFO:__main__:Imputed data shape: (1422, 4)\n",
      "INFO:__main__:Imputed data shape: (483, 4)\n",
      "INFO:__main__:Imputed data shape: (1259, 4)\n",
      "INFO:__main__:Imputed data shape: (308, 4)\n",
      "INFO:__main__:Imputed data shape: (395, 4)\n",
      "INFO:__main__:Imputed data shape: (1434, 4)\n",
      "INFO:__main__:Imputed data shape: (574, 4)\n",
      "INFO:__main__:Imputed data shape: (62, 4)\n",
      "INFO:__main__:Imputed data shape: (1208, 4)\n",
      "INFO:__main__:Imputed data shape: (447, 4)\n",
      "INFO:__main__:Imputed data shape: (1260, 4)\n",
      "INFO:__main__:Imputed data shape: (326, 4)\n",
      "INFO:__main__:Imputed data shape: (363, 4)\n",
      "INFO:__main__:Imputed data shape: (1934, 4)\n",
      "INFO:__main__:Imputed data shape: (1131, 4)\n",
      "INFO:__main__:Imputed data shape: (1385, 4)\n",
      "INFO:__main__:Imputed data shape: (689, 4)\n",
      "INFO:__main__:Imputed data shape: (12, 4)\n",
      "INFO:__main__:Imputed data shape: (1526, 4)\n",
      "INFO:__main__:Imputed data shape: (1621, 4)\n",
      "INFO:__main__:Imputed data shape: (1079, 4)\n",
      "INFO:__main__:Imputed data shape: (615, 4)\n",
      "INFO:__main__:Imputed data shape: (340, 4)\n",
      "INFO:__main__:Imputed data shape: (386, 4)\n",
      "INFO:__main__:Imputed data shape: (338, 4)\n",
      "INFO:__main__:Imputed data shape: (322, 4)\n",
      "INFO:__main__:Imputed data shape: (585, 4)\n",
      "INFO:__main__:Imputed data shape: (1485, 4)\n",
      "INFO:__main__:Imputed data shape: (256, 4)\n",
      "INFO:__main__:Imputed data shape: (292, 4)\n",
      "INFO:__main__:Imputed data shape: (1836, 4)\n",
      "INFO:__main__:Imputed data shape: (388, 4)\n",
      "INFO:__main__:Imputed data shape: (337, 4)\n",
      "INFO:__main__:Imputed data shape: (500, 4)\n",
      "INFO:__main__:Imputed data shape: (955, 4)\n",
      "INFO:__main__:Imputed data shape: (1167, 4)\n",
      "INFO:__main__:Imputed data shape: (340, 4)\n",
      "INFO:__main__:Imputed data shape: (270, 4)\n",
      "INFO:__main__:Imputed data shape: (980, 4)\n",
      "INFO:__main__:Imputed data shape: (1704, 4)\n",
      "INFO:__main__:Imputed data shape: (1254, 4)\n",
      "INFO:__main__:Imputed data shape: (1005, 4)\n",
      "INFO:__main__:Imputed data shape: (1898, 4)\n",
      "INFO:__main__:Imputed data shape: (1833, 4)\n",
      "INFO:__main__:Imputed data shape: (337, 4)\n",
      "INFO:__main__:Imputed data shape: (949, 4)\n",
      "INFO:__main__:Imputed data shape: (498, 4)\n",
      "INFO:__main__:Imputed data shape: (486, 4)\n",
      "INFO:__main__:Imputed data shape: (2039, 4)\n",
      "INFO:__main__:Imputed data shape: (625, 4)\n",
      "INFO:__main__:Imputed data shape: (1845, 4)\n",
      "INFO:__main__:Imputed data shape: (1064, 4)\n",
      "INFO:__main__:Imputed data shape: (382, 4)\n",
      "INFO:__main__:Imputed data shape: (1756, 4)\n",
      "INFO:__main__:Imputed data shape: (1541, 4)\n",
      "INFO:__main__:Imputed data shape: (513, 4)\n",
      "INFO:__main__:Imputed data shape: (2002, 4)\n",
      "INFO:__main__:Imputed data shape: (1811, 4)\n",
      "INFO:__main__:Imputed data shape: (396, 4)\n",
      "INFO:__main__:Imputed data shape: (1055, 4)\n",
      "INFO:__main__:Imputed data shape: (861, 4)\n",
      "INFO:__main__:Imputed data shape: (1016, 4)\n",
      "INFO:__main__:Imputed data shape: (600, 4)\n",
      "INFO:__main__:Imputed data shape: (321, 4)\n",
      "INFO:__main__:Imputed data shape: (613, 4)\n",
      "INFO:__main__:Imputed data shape: (372, 4)\n",
      "INFO:__main__:Imputed data shape: (975, 4)\n",
      "INFO:__main__:Imputed data shape: (346, 4)\n",
      "INFO:__main__:Imputed data shape: (274, 4)\n",
      "INFO:__main__:Imputed data shape: (1535, 4)\n",
      "INFO:__main__:Imputed data shape: (1247, 4)\n",
      "INFO:__main__:Imputed data shape: (319, 4)\n",
      "INFO:__main__:Imputed data shape: (278, 4)\n",
      "INFO:__main__:Imputed data shape: (93, 4)\n",
      "INFO:__main__:Imputed data shape: (624, 4)\n",
      "INFO:__main__:Imputed data shape: (199, 4)\n",
      "INFO:__main__:Imputed data shape: (979, 4)\n",
      "INFO:__main__:Imputed data shape: (2036, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def impute_time_series_data(df):\n",
    "    def get_neighbor_values(df, index, column):\n",
    "        neighbors = []\n",
    "        index_list = df.index.tolist()\n",
    "        current_index_position = index_list.index(index)\n",
    "\n",
    "        if current_index_position > 0:\n",
    "            prev_index = index_list[current_index_position - 1]\n",
    "            neighbors.extend(\n",
    "                [df.loc[prev_index, \"Morning\"], df.loc[prev_index, \"Afternoon\"]]\n",
    "            )\n",
    "\n",
    "        if current_index_position < len(index_list) - 1:\n",
    "            next_index = index_list[current_index_position + 1]\n",
    "            neighbors.extend(\n",
    "                [df.loc[next_index, \"Morning\"], df.loc[next_index, \"Afternoon\"]]\n",
    "            )\n",
    "\n",
    "        if column == \"Morning\" and pd.notna(df.loc[index, \"Afternoon\"]):\n",
    "            neighbors.append(df.loc[index, \"Afternoon\"])\n",
    "        elif column == \"Afternoon\" and pd.notna(df.loc[index, \"Morning\"]):\n",
    "            neighbors.append(df.loc[index, \"Morning\"])\n",
    "\n",
    "        return [x for x in neighbors if pd.notna(x)]\n",
    "\n",
    "    for column in [\"Morning\", \"Afternoon\"]:\n",
    "        for index in df.index:\n",
    "            if pd.isna(df.loc[index, column]):\n",
    "                neighbor_values = get_neighbor_values(df, index, column)\n",
    "                if neighbor_values:\n",
    "                    imputed_value = round(sum(neighbor_values) / len(neighbor_values))\n",
    "                    df.loc[index, column] = imputed_value\n",
    "\n",
    "    logger.info(f\"Imputed data shape: {df.shape}\")\n",
    "    df.to_csv(f\"2024-Data-Cleaned/Imputed_Data/{patient_id}-recent-Imputed.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the imputation to each patient's data\n",
    "imputed_patient_data_dict = {}\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "imputed_Data_dir = \"2024-Data-Cleaned/Imputed_Data\"\n",
    "os.makedirs(imputed_Data_dir, exist_ok=True)\n",
    "\n",
    "for patient_id, patient_df in cleaned_patient_data_dict.items():\n",
    "    imputed_patient_data_dict[patient_id] = impute_time_series_data(patient_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient Perf Data Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Total_Rows</th>\n",
       "      <th>Null_Morning</th>\n",
       "      <th>Null_Afternoon</th>\n",
       "      <th>Null_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SB-001</td>\n",
       "      <td>1336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB-002</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SB-003</td>\n",
       "      <td>1064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB-004</td>\n",
       "      <td>1823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SB-005</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SB-118</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SB-119</td>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SB-120</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SB-121</td>\n",
       "      <td>979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SB-122</td>\n",
       "      <td>2036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Total_Rows  Null_Morning  Null_Afternoon  Null_Other\n",
       "0      SB-001        1336             0               0        1336\n",
       "1      SB-002         572             0               0         572\n",
       "2      SB-003        1064             0               0        1064\n",
       "3      SB-004        1823             0               0        1823\n",
       "4      SB-005         281             0               0         281\n",
       "..        ...         ...           ...             ...         ...\n",
       "95     SB-118          93             0               0          93\n",
       "96     SB-119         624             0               0         624\n",
       "97     SB-120         199             0               0         199\n",
       "98     SB-121         979             0               0         973\n",
       "99     SB-122        2036             0               0        2034\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient Perf Data Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Total_Rows</th>\n",
       "      <th>Null_Morning</th>\n",
       "      <th>Null_Afternoon</th>\n",
       "      <th>Null_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SB-001</td>\n",
       "      <td>1336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB-002</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SB-003</td>\n",
       "      <td>1064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB-004</td>\n",
       "      <td>1823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SB-005</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SB-118</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SB-119</td>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SB-120</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SB-121</td>\n",
       "      <td>979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SB-122</td>\n",
       "      <td>2036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Total_Rows  Null_Morning  Null_Afternoon  Null_Other\n",
       "0      SB-001        1336             0               0        1336\n",
       "1      SB-002         572             0               0         572\n",
       "2      SB-003        1064             0               0        1064\n",
       "3      SB-004        1823             0               0        1823\n",
       "4      SB-005         281             0               0         281\n",
       "..        ...         ...           ...             ...         ...\n",
       "95     SB-118          93             0               0          93\n",
       "96     SB-119         624             0               0         624\n",
       "97     SB-120         199             0               0         199\n",
       "98     SB-121         979             0               0         973\n",
       "99     SB-122        2036             0               0        2034\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_patient_summary(patient_data_dict, output_file):\n",
    "    summary_data = []\n",
    "\n",
    "    for patient_id, patient_data in patient_data_dict.items():\n",
    "        row_count = len(patient_data)\n",
    "        null_morning = patient_data[\"Morning\"].isna().sum()\n",
    "        null_afternoon = patient_data[\"Afternoon\"].isna().sum()\n",
    "        null_other = patient_data[\"Other\"].isna().sum()\n",
    "\n",
    "        summary_data.append(\n",
    "            {\n",
    "                \"Patient_ID\": patient_id,\n",
    "                \"Total_Rows\": row_count,\n",
    "                \"Null_Morning\": null_morning,\n",
    "                \"Null_Afternoon\": null_afternoon,\n",
    "                \"Null_Other\": null_other,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Display the summary dataframe\n",
    "    print(\"\\nPatient Perf Data Summary:\")\n",
    "    display(summary_df)\n",
    "\n",
    "    # Optional: Save to CSV\n",
    "    summary_df.to_csv(output_file, index=False)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "output_file = \"2024-Data-Cleaned/cleaned_patient_perf_data_summary.csv\"\n",
    "# Create the summary dataframe\n",
    "patient_summary = create_patient_summary(cleaned_patient_data_dict, output_file)\n",
    "\n",
    "output_file = \"2024-Data-Cleaned/imputed_patient_perf_data_summary.csv\"\n",
    "# Create the summary dataframe\n",
    "patient_summary = create_patient_summary(imputed_patient_data_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def combine_patient_dataframes(patient_data_dict, output_file):\n",
    "    # Create a list to store all dataframes\n",
    "    all_dataframes = []\n",
    "\n",
    "    # Iterate through the dictionary\n",
    "    for patient_id, df in patient_data_dict.items():\n",
    "        # Add a new column for patient ID\n",
    "        df[\"Patient_ID\"] = patient_id\n",
    "\n",
    "        # Append the dataframe to our list\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    # Reorder columns to have Patient_ID first\n",
    "    columns_order = [\"Patient_ID\"] + [\n",
    "        col for col in combined_df.columns if col != \"Patient_ID\"\n",
    "    ]\n",
    "    combined_df = combined_df[columns_order]\n",
    "\n",
    "    # Display the first few rows of the combined dataframe\n",
    "    combined_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "output_file = \"2024-Data-Cleaned/combined_cleaned_patient_asthma_data.csv\"\n",
    "\n",
    "# Use the function to create the combined dataframe\n",
    "combined_patient_data = combine_patient_dataframes(\n",
    "    cleaned_patient_data_dict, output_file\n",
    ")\n",
    "\n",
    "output_file = \"2024-Data-Cleaned/combined_imputed_patient_asthma_data.csv\"\n",
    "\n",
    "# Use the function to create the combined dataframe\n",
    "combined_imputed_patient_data = combine_patient_dataframes(\n",
    "    imputed_patient_data_dict, output_file\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
