{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\program files\\python312\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python312\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: seaborn in c:\\program files\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\program files\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\program files\\python312\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\program files\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\41222\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\program files\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\program files\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script execution...\n",
      "Loading data...\n",
      "Available columns in the DataFrame:\n",
      "Index(['ID', 'Age', 'Sex', 'Smoke', 'Smoke_amount', 'Height', 'Weight', 'BMI',\n",
      "       'BSA', 'occupation', 'address', 'Date', 'Morning_PEFR',\n",
      "       'Afternoon_PEFR', 'Other_PEFR'],\n",
      "      dtype='object')\n",
      "Preprocessing data...\n",
      "Handling missing values...\n",
      "Normalizing features...\n",
      "Starting grid search...\n",
      "Testing combination 1/24: {'affinity': 'rbf', 'gamma': 0.1, 'n_clusters': 2}\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 59.4 GiB for an array with shape (89317, 89317) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub_Repos\\jay-singhvi\\schas-2024-asthama-2.0\\spectral_clustering.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal execution time: \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\GitHub_Repos\\jay-singhvi\\schas-2024-asthama-2.0\\spectral_clustering.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTesting combination \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_combinations\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mparams\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m spectral \u001b[39m=\u001b[39m SpectralClustering(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m labels \u001b[39m=\u001b[39m spectral\u001b[39m.\u001b[39;49mfit_predict(X_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m score \u001b[39m=\u001b[39m calinski_harabasz_score(X_scaled, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub_Repos/jay-singhvi/schas-2024-asthama-2.0/spectral_clustering.ipynb#W1sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mif\u001b[39;00m score \u001b[39m>\u001b[39m best_score:\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:791\u001b[0m, in \u001b[0;36mSpectralClustering.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    770\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform spectral clustering on `X` and return cluster labels.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \n\u001b[0;32m    772\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[39m        Cluster labels.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_predict(X, y)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\base.py:900\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[39m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    901\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:729\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    727\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39mdegree\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree\n\u001b[0;32m    728\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39mcoef0\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef0\n\u001b[1;32m--> 729\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffinity_matrix_ \u001b[39m=\u001b[39m pairwise_kernels(\n\u001b[0;32m    730\u001b[0m         X, metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maffinity, filter_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[0;32m    731\u001b[0m     )\n\u001b[0;32m    733\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[0;32m    734\u001b[0m n_components \u001b[39m=\u001b[39m (\n\u001b[0;32m    735\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components\n\u001b[0;32m    736\u001b[0m )\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2522\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   2519\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mcallable\u001b[39m(metric):\n\u001b[0;32m   2520\u001b[0m     func \u001b[39m=\u001b[39m partial(_pairwise_callable, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 2522\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1871\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1868\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1870\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1871\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1873\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1540\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[39mif\u001b[39;00m gamma \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1538\u001b[0m     gamma \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1540\u001b[0m K \u001b[39m=\u001b[39m euclidean_distances(X, Y, squared\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1541\u001b[0m K \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mgamma\n\u001b[0;32m   1542\u001b[0m np\u001b[39m.\u001b[39mexp(K, K)  \u001b[39m# exponentiate K in-place\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:347\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[39mif\u001b[39;00m Y_norm_squared\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39m1\u001b[39m, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m    342\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible dimensions for Y of shape \u001b[39m\u001b[39m{\u001b[39;00mY\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mY_norm_squared of shape \u001b[39m\u001b[39m{\u001b[39;00moriginal_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m         )\n\u001b[1;32m--> 347\u001b[0m \u001b[39mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:382\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    379\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    380\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    383\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[0;32m    384\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    206\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[0;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    211\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[0;32m    212\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    213\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[0;32m    214\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m ):\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 59.4 GiB for an array with shape (89317, 89317) and data type float64"
     ]
    }
   ],
   "source": [
    "# version 3 - A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Starting script execution...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load the data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(\"2024-Data-Cleaned/merged_patient_data.csv\")\n",
    "\n",
    "    # Print available columns\n",
    "    print(\"Available columns in the DataFrame:\")\n",
    "    print(df.columns)\n",
    "\n",
    "    # Preprocess the data\n",
    "    print(\"Preprocessing data...\")\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({\"M\": 0, \"F\": 1})\n",
    "    df[\"Smoke\"] = df[\"Smoke\"].map({\"NS\": 0, \"ES\": 1})\n",
    "\n",
    "    # Select features for clustering\n",
    "    features = [\n",
    "        \"Age\",\n",
    "        \"Sex\",\n",
    "        \"Smoke\",\n",
    "        \"Smoke_amount\",\n",
    "        \"Height\",\n",
    "        \"Weight\",\n",
    "        \"BMI\",\n",
    "        \"BSA\",\n",
    "        \"Morning_PEFR\",\n",
    "        \"Afternoon_PEFR\",\n",
    "    ]\n",
    "    X = df[features]\n",
    "\n",
    "    # Handle missing values\n",
    "    print(\"Handling missing values...\")\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Normalize the features\n",
    "    print(\"Normalizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        \"n_clusters\": [2, 4, 5, 8],\n",
    "        \"affinity\": [\"rbf\", \"nearest_neighbors\"],\n",
    "        \"gamma\": [0.1, 1, 10],\n",
    "    }\n",
    "\n",
    "    # Perform manual grid search\n",
    "    print(\"Starting grid search...\")\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    total_combinations = len(list(ParameterGrid(param_grid)))\n",
    "\n",
    "    for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "        print(f\"Testing combination {i+1}/{total_combinations}: {params}\")\n",
    "        spectral = SpectralClustering(**params, random_state=42, n_jobs=-1)\n",
    "        labels = spectral.fit_predict(X_scaled)\n",
    "        score = calinski_harabasz_score(X_scaled, labels)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "\n",
    "    print(\"Grid search completed.\")\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best Calinski-Harabasz score:\", best_score)\n",
    "\n",
    "    # Use the best parameters to perform the final clustering\n",
    "    print(\"Performing final clustering...\")\n",
    "    best_spectral = SpectralClustering(**best_params, random_state=42, n_jobs=-1)\n",
    "    df[\"Cluster\"] = best_spectral.fit_predict(X_scaled)\n",
    "\n",
    "    print(\"Clustering completed.\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # version 2 - A\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cluster import SpectralClustering\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import make_scorer, calinski_harabasz_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Load the data\n",
    "# df = pd.read_csv(\"2024-Data-Cleaned/merged_patient_data.csv\")\n",
    "\n",
    "# # Print available columns\n",
    "# print(\"Available columns in the DataFrame:\")\n",
    "# print(df.columns)\n",
    "\n",
    "# # Preprocess the data\n",
    "# df[\"Sex\"] = df[\"Sex\"].map({\"M\": 0, \"F\": 1})\n",
    "# df[\"Smoke\"] = df[\"Smoke\"].map({\"NS\": 0, \"ES\": 1})\n",
    "\n",
    "# # Select features for clustering\n",
    "# features = [\n",
    "#     \"Age\",\n",
    "#     \"Sex\",\n",
    "#     \"Smoke\",\n",
    "#     \"Smoke_amount\",\n",
    "#     \"Height\",\n",
    "#     \"Weight\",\n",
    "#     \"BMI\",\n",
    "#     \"BSA\",\n",
    "#     \"Morning_PEFR\",\n",
    "#     \"Afternoon_PEFR\",\n",
    "# ]\n",
    "# X = df[features]\n",
    "\n",
    "# # Handle missing values\n",
    "# imputer = SimpleImputer(strategy=\"mean\")\n",
    "# X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     \"n_clusters\": [2, 4, 5, 8],\n",
    "#     \"affinity\": [\"rbf\", \"nearest_neighbors\"],\n",
    "#     # \"n_neighbors\": [5, 10, 15],\n",
    "#     \"gamma\": [0.1, 1, 10],\n",
    "# }\n",
    "\n",
    "# # Define a custom scorer (we'll use the Calinski-Harabasz Index)\n",
    "# ch_scorer = make_scorer(calinski_harabasz_score)\n",
    "\n",
    "# # Perform Grid Search\n",
    "# spectral = SpectralClustering(random_state=42)\n",
    "# grid_search = GridSearchCV(spectral, param_grid, scoring=ch_scorer, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_scaled)\n",
    "\n",
    "# # Get the best parameters and score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best parameters:\", best_params)\n",
    "# print(\"Best Calinski-Harabasz score:\", best_score)\n",
    "\n",
    "# # Use the best parameters to perform the final clustering\n",
    "# best_spectral = SpectralClustering(**best_params, random_state=42)\n",
    "# df[\"Cluster\"] = best_spectral.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters\n",
    "cluster_summary = df.groupby(\"Cluster\")[features].mean()\n",
    "print(\"\\nCluster Summary:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Visualize clusters using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df[\"Cluster\"], cmap=\"viridis\")\n",
    "plt.title(\"Spectral Clustering Results (PCA)\")\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.colorbar(scatter)\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature distributions across clusters\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=\"Cluster\", y=feature, data=df)\n",
    "    plt.title(f\"{feature} Distribution Across Clusters\")\n",
    "    plt.show()\n",
    "\n",
    "# Analyze PEFR trends within clusters\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "for cluster in df[\"Cluster\"].unique():\n",
    "    cluster_data = df[df[\"Cluster\"] == cluster]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cluster_data[\"Date\"], cluster_data[\"Morning_PEFR\"], label=\"Morning PEFR\")\n",
    "    plt.plot(\n",
    "        cluster_data[\"Date\"], cluster_data[\"Afternoon_PEFR\"], label=\"Afternoon PEFR\"\n",
    "    )\n",
    "    plt.title(f\"PEFR Trends for Cluster {cluster}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"PEFR\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Correlation analysis within clusters\n",
    "for cluster in df[\"Cluster\"].unique():\n",
    "    cluster_data = df[df[\"Cluster\"] == cluster]\n",
    "    correlation = cluster_data[features].corr()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, center=0)\n",
    "    plt.title(f\"Correlation Heatmap for Cluster {cluster}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
